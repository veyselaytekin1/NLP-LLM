{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain is a framework\n",
    "# Wir können es mit Huggingface models and OpenAI models verwenden\n",
    "# und macht die Integration zwischen unseren File, application, our api data und LLM\n",
    "# Zum Beispiel werden wir unten eine Beispiel machen. In diesen Beispiel verbinden wir unsere OpenAI LLM\n",
    "# with google search result with eine Python library called google-search-results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openai\n",
    "# ! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Language Model Application\n",
    "#### LLMS : Get predictions from a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rome, Italy \n",
      "2. Bologna, Italy \n",
      "3. Florence, Italy \n",
      "4. Venice, Italy \n",
      "5. Naples, Italy\n"
     ]
    }
   ],
   "source": [
    "text = 'What are  5 vacation destinations for someone who likes to eat pasta?'\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = ['food'],\n",
    "    template= 'What are 5 vacation destinations for someone who likes to eat {food}?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat ['dessert']?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=['dessert']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France - renowned for its desserts such as crepes, éclairs, macarons, and more.\n",
      "\n",
      "2. Tokyo, Japan - a great destination for all sorts of desserts from traditional Japanese sweets to modern creations.\n",
      "\n",
      "3. Lujiazui, China - known as “Dessert Heaven”, this area is filled with bakeries and cafés devoted to sweet treats like ice cream, cakes, and more.\n",
      "\n",
      "4. Bali, Indonesia - home to some of the most unique and exciting desserts like pandan cake, tropical coconut desserts, and sticky rice treats.\n",
      "\n",
      "5. New York City, USA - the city that never sleeps offers some of the world’s best ice cream, cheesecakes, cupcakes, and more.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=['dessert'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains : Combine LLMs and promts in multi-step workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['foof'],\n",
    "    template='What are 5 vacation destinations for someone who likes to eat {food}?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. The Caribbean - There are so many delicious fruits found in the Caribbean like mango, papaya, pineapple, guava, and coconuts.\n",
      "\n",
      "2. South Africa - South Africa has an abundance of fresh, delicious fruits such as apricots, litchi, mangoes, and more.\n",
      "\n",
      "3. Thailand - There are many exotic fruits like durian, rambutan, mangosteen, and more to try in Thailand.\n",
      "\n",
      "4. Mexico - Mexico is a great destination for fruit-lovers, with tons of tropical fruits like bananas, plantains, papayas and more.\n",
      "\n",
      "5. The Mediterranean - The Mediterranean offers plenty of delicious citrus fruits, figs, pomegranates, and olives.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run('fruit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents : Dynamically call chains based on user input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We get with google-search-results python library the google's results than use our model this infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# serpapi is for google search\n",
    "os.environ['SERPAPI_API_KEY'] = 'dd31ad86692e4ad26e6e2a99aba7aaebffe5ffdc5cf6230f44fb8f34c859ac8c'\n",
    "\n",
    "tools  = load_tools(['serpapi', 'llm-math'], llm=llm)\n",
    "\n",
    "# google sonuclarina erismek icin kullanioyruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, tags=['zero-shot-react-description'], agent=ZeroShotAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7f9bb8c26f10>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f9ba88ffb20>, temperature=0.0, openai_api_key='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', openai_proxy='')), output_parser=MRKLOutputParser(), allowed_tools=['Search', 'Calculator']), tools=[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='dd31ad86692e4ad26e6e2a99aba7aaebffe5ffdc5cf6230f44fb8f34c859ac8c', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='dd31ad86692e4ad26e6e2a99aba7aaebffe5ffdc5cf6230f44fb8f34c859ac8c', aiosession=None)>), Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7f9bb8c26f10>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f9ba88ffb20>, temperature=0.0, openai_api_key='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', openai_proxy='')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7f9bb8c26f10>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7f9ba88ffb20>, temperature=0.0, openai_api_key='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', openai_proxy='')))>)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(tools, llm, agent='zero-shot-react-description', verbose=True)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the leader of Japan is and then calculate the largest prime number that is smaller than their age.\n",
      "Action: Search\n",
      "Action Input: \"Current leader of Japan\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFumio Kishida is the current prime minister of Japan, replacing Yoshihide Suga on 4 October 2021. As of 22 December 2023, there have been 64 individual prime ministers serving 101 terms of office.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the largest prime number that is smaller than the prime minister's age.\n",
      "Action: Calculator\n",
      "Action Input: 64\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 64\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 64.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current leader of Japan is Fumio Kishida and the largest prime number that is smaller than their age is 64.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out\n",
    "agent.run('Who is the current leader of japan? What is the largest prime number that is smaller than their age?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory : Add state to chains and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: I'm doing well. Just having a conversation with an AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's great! It's always nice to have a conversation with someone. What would you like to talk about?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm doing well. Just having a conversation with an AI\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: I'm doing well. Just having a conversation with an AI\n",
      "AI:  That's great! It's always nice to have a conversation with someone. What would you like to talk about?\n",
      "Human: What was the first thing I said to you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You said \"Hi there\"!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What was the first thing I said to you?\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Components\n",
    "#### Schema - Nuts and Bolts of working with LLMs\n",
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with simple strings (that'll soon frow in complexity)\n",
    "my_text = 'What day comes after Freiday?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Messages\n",
    "System message : this background context that tell the AI what to do  \n",
    "\n",
    "\n",
    "Human : input comes from user  \n",
    "\n",
    "AI : Output comes from AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7, openai_api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You could try a fresh Caprese salad with tomatoes, mozzarella, and basil.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [SystemMessage(content='You are a nice AI bot that helps a user figure out what to eat in one short sentence'),\n",
    "    HumanMessage(content='I like tomatoes, what should I eat?')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass more chat history responses from the AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auf Deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Wenn du in Nizza bist, gibt es viele Aktivitäten, die du genießen kannst. Hier sind einige Vorschläge:\\n\\n1. Erkunde die Altstadt (Vieux Nice): Schlendere durch die engen Gassen, bewundere die bunten Gebäude und besuche den berühmten Blumenmarkt.\\n\\n2. Besuche den Promenade des Anglais: Diese berühmte Strandpromenade erstreckt sich entlang der Küste von Nizza und bietet einen atemberaubenden Blick auf das Meer. Du kannst hier spazieren gehen, Rad fahren oder einfach nur die Sonne genießen.\\n\\n3. Entdecke die Museen: Nizza beherbergt eine Vielzahl von Museen, darunter das Musée Matisse, das Musée d'Art Moderne et d'Art Contemporain und das Musée Marc Chagall. Hier kannst du die Werke bekannter Künstler bewundern.\\n\\n4. Besuche den Markt Cours Saleya: Dieser Markt ist berühmt für seine frischen Lebensmittel, lokale Produkte und Blumen. Hier kannst du lokale Spezialitäten probieren und Souvenirs kaufen.\\n\\n5. Genieße die lokale Küche: Nizza ist bekannt für seine köstliche Küche, insbesondere für Gerichte wie Salade Niçoise, Socca (eine Art Kichererbsenpfannkuchen) und Ratatouille. Probiere unbedingt diese lokalen Spezialitäten.\\n\\n6. Mach einen Ausflug nach Monaco: Nizza liegt in der Nähe von Monaco, einem kleinen Fürstentum, das für seinen Glamour und seine Casinos bekannt ist. Du kannst einen Tagesausflug nach Monaco unternehmen und die Sehenswürdigkeiten wie das Casino von Monte Carlo und den Fürstenpalast besichtigen.\\n\\nDas sind nur einige der vielen Möglichkeiten, wie du deine Zeit in Nizza verbringen kannst. Es gibt noch viel mehr zu entdecken und zu erleben.\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content='Du bist eine schöne AI bot. Du hilfst die users'),\n",
    "        HumanMessage(content='I würde gern reisen?'),\n",
    "        AIMessage(content= 'Du sollst nach Nice, Frankreich fahren'),\n",
    "        HumanMessage(content='Was mache ich, wenn ich da wäre?')\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7c19a79b9aeb8b1cc18eda6778f62d726c8b19540b84d23ad80114035b2e0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
