{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Multi-doc retriever with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env dosyasını yükle\n",
    "load_dotenv()\n",
    "\n",
    "# Ortam değişkenini al\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some files for a source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
    "# ! unzip -q new_articles.zip -d new_articles\n",
    "\n",
    "# burdan bir dropbox kaynagondan kullanmak icin rastgele dosyalr indirdik .txt formatinda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load multiple and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='The best way to avoid a down round is to found an AI startup\\n\\nAs we see unicorns slash staff and the prevalence of down rounds spike, it may seem that the startup ecosystem is chock-full of bad news and little else. That’s not precisely the case.\\n\\nWhile AI, and in particular the generative AI subcategory, are as hot as the sun, not all venture attention is going to the handful of names that you already know. Sure, OpenAI is able to land nine and 10-figure rounds from a murderer’s row of tech investors and mega-cap corporations. And rising companies like Hugging Face and Anthropic cannot stay out of the news, proving that smaller AI-focused startups are doing more than well.\\n\\nIn fact, new data from Carta, which provides cap table management and other services, indicates that AI-focused startups are outperforming their larger peer group at both the seed and Series A stage.\\n\\nThe dataset, which notes that AI-centered startups are raising more and at higher valuations than other startups, indicates that perhaps the best way to avoid a down round today is to build in the artificial intelligence space.\\n\\nWhat the data says\\n\\nPer Carta data relating to the first quarter of the year, seed funding to non-AI startups in the U.S. market that use its services dipped from $1.64 billion to $1.08 billion, or a decline of around 34%. That result is directionally aligned with other data that we’ve seen regarding Q1 2023 venture capital totals; the data points down.', metadata={'source': 'new_articles/05-06-ai-startups-q1-investments.txt'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process the text files\n",
    "# loader = TExtloader('single_text_file.txt')\n",
    "\n",
    "loader = DirectoryLoader('./new_articles/', glob='./*txt', loader_cls=TextLoader) # pdf varsa PDFloader gibi biseyde var ama netten bak)\n",
    "\n",
    "documents = loader.load()\n",
    "documents[1]\n",
    "\n",
    "# burda tüm textleri bir yere topluyor. \n",
    "# mesela documents[1] bunu yapinca new_articles dosysindan bir dosyanin tamamini getirdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents) \n",
    "# burda bütün metinlerin toplami var ama\n",
    "# ama chunklara ayrilmis durumda. her 1000 karakter 1 chunk oluyor\n",
    "\n",
    "len(texts) #yani toplamda 233 chunks oldu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the text\n",
    "# Supplying a persist directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "embedding = OpenAIEmbeddings()   \n",
    "# OpenAI embeddings modelini kullaniyoruz. onun kendine ait embeddings kümesi var ve tokenizer\n",
    "# bununla PDF ler ele aliniyor ve anlamlari ele aliniyor\n",
    " \n",
    "vectordb = Chroma.from_documents(documents = texts, # bizim PDF lerin toplami\n",
    "                                 embedding = embedding, \n",
    "                                 persist_directory = persist_directory)\n",
    "\n",
    "# burda texts embeddings ile vectörlere cevrilir ve Chroma db e kaydedilir\n",
    "# ve calistirinca bir 'db' adinda bir database olusturulur ve icine kaydedilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7c19a79b9aeb8b1cc18eda6778f62d726c8b19540b84d23ad80114035b2e0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
